{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1 \n",
    "### Introduction to the problem/task and dataset\n",
    "\n",
    "PumpkinSeed-ML-Insights is a comprehensive repository dedicated to the exploration and analysis of Turkish pumpkin seed varieties, with a focus on classifying whether a seed belongs to Urgup Sivrisi or Cercevelik species. This project demonstrates the knowledge of authors in data science and machine learning.\n",
    "\n",
    "Within this repository, you will find a Jupyter Notebook that serves as a self-explanatory document, guiding you through the entire process. This repository also contains three Python files, each implementing a different machine learning model: `knn_pumpkinseed.py`, `logistic_regression_pumkinseed.py`, and `neural_network_pumpkinseed.py`. There is also the `pumpkin_seeds.csv`, which contains the data and `Pumpkin_seeds.pdf`, which contains some description of the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 2\n",
    "### Description of the dataset\n",
    "\n",
    "`pumpkin_seeds.csv` is a CSV file containing information about Pumpkin Seeds found in Turkey. \n",
    "\n",
    "This dataset came from the study `The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.).` by Koklu, M., Sarigil, S., & Ozbek, O. in 2021. In their paper, they used a product shooting box to obtain quality images of the pumpkin seeds. The authors converted the images to a gray tone and then to binary images. To convert the image data into a CSV file, they extracted 12 morphological features.\n",
    "\n",
    "Overall, the CSV file has 13 columns/features and 2500 rows. The first 12 columns are from the extracted morphological features, while the last column classifies whether it belongs to the Urgup Sivrisi or Cercevelik species. There are 2500 rows, representing a single seed used in the study. There are 1200 Urgup Sivrisi and 1300 Cercevelik species of pumpkin seeds. \n",
    "\n",
    "The features found in this CSV file are as follows:\n",
    "1. Area ‚Äì Number of pixels within the borders of a pumpkin seed\n",
    "2. Perimeter ‚Äì Circumference in pixels of a pumpkin seed\n",
    "3. Major_Axis_Length ‚Äì Large axis distance of a pumpkin seed\n",
    "4. Minor_Axis_Length ‚Äì Small axis distance of a pumpkin seed\n",
    "5. Convex_Area ‚Äì Number of pixels of the smallest convex shell at the region formed by the\n",
    "pumpkin seed.\n",
    "6. Equiv_Diameter ‚Äì Computed as !4ùëé‚ÅÑùúã, where ùëé is the area of the pumpkin seed.\n",
    "7. Eccentricity ‚Äì Eccentricity of a pumpkin seed\n",
    "8. Solidity ‚Äì Convex condition of the pumpkin seeds\n",
    "9. Extent ‚Äì Ratio of a pumpkin seed area to the bounding box pixels\n",
    "10. Roundness ‚Äì Ovality of pumpkin seeds without considering the distortion of the edges.\n",
    "11. Aspect_Ration ‚Äì Aspect ratio of the pumpkin seeds\n",
    "12. Compactness ‚Äì Proportion of the area of the pumpkin seed relative to the area of the circle\n",
    "with the same circumference\n",
    "13. Class ‚Äì Either Cercevelik or Urgup Sivrisi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 3\n",
    "\n",
    "### List of Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 4\n",
    "\n",
    "### Data preprocessing and cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to address the encoding issues, especially in the \"Class\" column. The unique values in the \"Class\" column are showing encoding issues, as evidenced by the presence of escape characters like \\x82. These values are intended to represent the two species of pumpkin seeds. To correct this, we need to replace these incorrectly encoded strings with a correct format. We replaced the string class names with an integer value of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('pumpkin_seeds.csv', 'r', encoding='utf-8', errors='replace') as csv_file:\n",
    "    raw_data = csv.reader(csv_file)\n",
    "\n",
    "    #Skip headers\n",
    "    next(raw_data)\n",
    "\n",
    "    #Store data into data array\n",
    "    for row in raw_data:\n",
    "        row_data = []\n",
    "        for i in range(13): #Convert errors into 1 or 2 (depending on their specie)\n",
    "            if i == 12 and row[i] == 'ÔøΩerÔøΩevelik':\n",
    "                row_data.append(int(0))\n",
    "            elif i == 12 and row[i] == 'ÔøΩrgÔøΩp Sivrisi':\n",
    "                row_data.append(int(1))\n",
    "            else:\n",
    "                row_data.append(row[i])\n",
    "\n",
    "        data.append(row_data)\n",
    "\n",
    "#Convert data into numpy array\n",
    "np_data = np.array(data)\n",
    "np_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling\n",
    "\n",
    "The numerical features are scaled using `StandardScaler` from `sklearn.preprocessing`. This ensures that all features have a mean of 0 and a standard deviation of 1, which is particularly important for many machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Replace 'original_column_names' with the actual list of column names\n",
    "original_column_names = ['area', 'perimeter', 'major_axis_length', 'minor_axis_length', \n",
    "                         'convex_area', 'equiv_diameter', 'eccentricity', 'solidity', \n",
    "                         'extent', 'roundness', 'aspect_Ration', 'compactness', 'class']\n",
    "\n",
    "# Convert the numpy array to a pandas DataFrame using the original column names\n",
    "pumpkin_seeds_data = pd.DataFrame(np_data, columns=original_column_names)\n",
    "\n",
    "# Selecting only the numerical features for scaling\n",
    "numerical_features = pumpkin_seeds_data.iloc[:, :-1]\n",
    "\n",
    "# Initializing the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling the numerical features\n",
    "scaled_numerical_features = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Creating a new DataFrame with scaled values using the original column names (excluding 'class')\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical_features, columns=original_column_names[:-1])\n",
    "\n",
    "# Adding the non-numerical column ('class') back to the DataFrame\n",
    "scaled_pumpkin_seeds_data = pd.concat([scaled_numerical_df, pumpkin_seeds_data['class']], axis=1)\n",
    "\n",
    "scaled_pumpkin_seeds_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data, it is now time to define our X and y variables. The X variable will hold the features, while the y variable contains our target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the feature set 'X' and the target 'y'\n",
    "X = scaled_pumpkin_seeds_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = scaled_pumpkin_seeds_data['class']      # Only the last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the training from the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('y_train shape', X_test.shape)\n",
    "print('X_test shape', y_train.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "## SECTION 5 - Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics\n",
    "Here, we examine the descriptive statistics of the numerical features. This includes measures like mean, median, standard deviation, and quartiles, which provide insights into the central tendency and spread of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics for Numerical Features\n",
    "descriptive_stats = scaled_pumpkin_seeds_data.describe()\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our exploratory data analysis, the descriptive statistics of the scaled pumpkin seed dataset reveal insightful trends and characteristics. Each feature, represented by 2,500 observations, exhibits a mean value near zero and a standard deviation close to one, a clear indication of effective standard scaling. This normalization is crucial for many machine learning algorithms as it ensures that all features contribute equally to the analysis without bias from differing scales. The minimum and maximum values across the features range significantly, suggesting a wide spread in the data, which is pivotal in understanding the distribution's extent and variance. While these scaled statistics inherently mask the actual raw values, they serve as a vital step in preparing the data for subsequent predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Distribution of Each Feature\n",
    "features = scaled_pumpkin_seeds_data.columns[:-1]  # Excluding the class column\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(scaled_pumpkin_seeds_data[feature], bins=20, alpha=0.7)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram visualizations of the scaled pumpkin seed dataset provide information into the distributions of each feature. These graphical representations, with their focus on frequency distributions, highlight key characteristics such as skewness, modality, and the spread of data. For features with distributions skewing left or right, we observe an asymmetrical spread, indicating a higher concentration of data points on one side of the mean. This skewness can be crucial in understanding the natural tendencies of certain features. Features exhibiting a more symmetrical distribution around the zero mark suggest a relatively even spread on both sides of the mean, implying no significant skewness. The presence of multiple peaks in some histograms hints at multimodality, which could be a sign of underlying subgroups within the data. Additionally, the spread and range of the data within these histograms, particularly any data points lying far from the central cluster, might signal outliers or unusual variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots for Each Feature\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=scaled_pumpkin_seeds_data[feature])\n",
    "    plt.title(f'Box Plot of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plots for each feature in our scaled pumpkin seed dataset offer valuable insights into the distribution characteristics of our data. Each plot vividly illustrates the median, quartiles, and potential outliers, providing a comprehensive view of data dispersion and central tendency. Features with wider boxes indicate greater dispersion in values, whereas narrower boxes suggest more uniform data. The whiskers extending from each box plot further reveal the range of the data, excluding outliers. Points that lie beyond these whiskers are marked as outliers, highlighting exceptional values that may warrant further investigation. These outliers could represent anomalies or unique characteristics of the dataset, and their presence is crucial for understanding the full scope of the data's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "## SECTION 6 - Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the KNN classifier\n",
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy of the model on the test data\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting arbitrary value (5) for the number of neighbors\n",
    "neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, data_index = model.kneighbors(X_test,neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top neighbors of the test data\n",
    "np.squeeze(distances)\n",
    "np.squeeze(data_index)\n",
    "print('Top 5 neighbors of the test data:')\n",
    "for i in range(len(5)):\n",
    "    print('Neighbor:', i+1)\n",
    "    print('Distance:', distances[i])\n",
    "    print('Data index:', data_index[i])\n",
    "    print('Class:', y_train.iloc[data_index[i]])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross validation libraries\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "scores = np.zeros((len(k_choices), k_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(k_choices)):\n",
    "    model = KNeighborsClassifier(n_neighbors=k_choices[i])\n",
    "    scores[i] = cross_val_score(model, X_train, y_train, cv=k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(scores):\n",
    "    for i in range(len(scores)):\n",
    "        x=[k_choices[i]] * 5\n",
    "        plt.scatter(x, scores[i])\n",
    "        \n",
    "plot_scatter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average scores of each fold\n",
    "avg_scores = np.mean(scores, axis=1)\n",
    "print('Average scores:', avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average accuracy for each k\n",
    "stddev_scores = np.std(scores, axis=1)\n",
    "print('Standard deviation of scores:', stddev_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(scores)\n",
    "\n",
    "plt.errorbar(k_choices, avg_scores, yerr=stddev_scores)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on selected k value\n",
    "model = KNeighborsClassifier(n_neighbors=12)\n",
    "\n",
    "# Training the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy of the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
